{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Week-4: Building a CNN for Image Classification\n",
        "- Design and implement a CNN model (with 4+ layers of convolutions) to classify multi category\n",
        "image datasets.\n",
        "- Use the Fashion MNIST dataset.\n",
        "- Set the number of Epoch as 5, 10 and 20.\n",
        "- Make the necessary changes whenever required. Record the accuracy corresponding to the number\n",
        "of epochs.\n",
        "- Record the time required to run the program, using CPU as well as using GPU in Colab."
      ],
      "metadata": {
        "id": "f2RrjLbzDOcH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fashion MNIST Dataset: https://www.kaggle.com/datasets/zalando-research/fashionmnist"
      ],
      "metadata": {
        "id": "1cWpHLUlRsOT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "\n",
        "from keras.datasets import fashion_mnist\n",
        "from keras.layers import Dense, Activation, Flatten, Conv2D, MaxPooling2D\n",
        "from keras.models import Sequential\n",
        "from keras.utils import to_categorical\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "(train_X,train_Y), (test_X,test_Y) = fashion_mnist.load_data()\n",
        "train_X = train_X.reshape(-1, 28,28, 1)\n",
        "test_X = test_X.reshape(-1, 28,28, 1)\n",
        "train_X = train_X.astype('float32')\n",
        "test_X = test_X.astype('float32')\n",
        "train_X = train_X / 255\n",
        "test_X = test_X / 255\n",
        "train_Y_one_hot = to_categorical(train_Y)\n",
        "test_Y_one_hot = to_categorical(test_Y)\n",
        "model = Sequential()\n",
        "model.add(Conv2D(256, (3,3), input_shape=(28, 28, 1)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Conv2D(128, (3,3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Conv2D(64, (3,3), input_shape=(28, 28, 1)))\n",
        "model.add(Activation('relu'))\n",
        "#model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Conv2D(28, (3,3)))\n",
        "model.add(Activation('relu'))\n",
        "#model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64))\n",
        "model.add(Dense(10))\n",
        "model.add(Activation('softmax'))\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "optimizer=keras.optimizers.Adam(),metrics=['accuracy'])\n",
        "model.fit(train_X, train_Y_one_hot, batch_size=64, epochs=5)\n",
        "test_loss, test_acc = model.evaluate(test_X, test_Y_one_hot)\n",
        "print('Test loss', test_loss)\n",
        "print('Test accuracy', test_acc)\n",
        "predictions = model.predict(test_X)\n",
        "print(np.argmax(np.round(predictions[0])))\n",
        "plt.imshow(test_X[0].reshape(28, 28), cmap = plt.cm.binary)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_P9i-MNtDQeu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.datasets import fashion_mnist\n",
        "from keras.layers import Dense, Activation, Flatten, Conv2D, MaxPooling2D\n",
        "from keras.models import Sequential\n",
        "from keras.utils import to_categorical\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load and preprocess data\n",
        "(train_X, train_Y), (test_X, test_Y) = fashion_mnist.load_data()\n",
        "train_X = train_X.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
        "test_X = test_X.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
        "\n",
        "train_Y_one_hot = to_categorical(train_Y)\n",
        "test_Y_one_hot = to_categorical(test_Y)\n",
        "\n",
        "# Build model with padding='same'\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(28, 28, 1)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "# No more MaxPooling here\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=keras.optimizers.Adam(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train\n",
        "model.fit(train_X, train_Y_one_hot, batch_size=64, epochs=5, validation_split=0.1)\n",
        "\n",
        "# Evaluate\n",
        "test_loss, test_acc = model.evaluate(test_X, test_Y_one_hot)\n",
        "print('Test loss:', test_loss)\n",
        "print('Test accuracy:', test_acc)\n",
        "\n",
        "# Prediction example\n",
        "predictions = model.predict(test_X)\n",
        "print('Predicted label for first test image:', np.argmax(predictions[0]))\n",
        "\n",
        "# Show first test image with prediction\n",
        "plt.imshow(test_X[0].reshape(28, 28), cmap=plt.cm.binary)\n",
        "plt.title(f'Predicted: {np.argmax(predictions[0])}')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 906
        },
        "id": "tgm4PepVMyvH",
        "outputId": "9f3541cd-a4b0-4dfb-b25e-025185301a9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 13ms/step - accuracy: 0.7533 - loss: 0.6720 - val_accuracy: 0.8742 - val_loss: 0.3393\n",
            "Epoch 2/5\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.9001 - loss: 0.2726 - val_accuracy: 0.9023 - val_loss: 0.2608\n",
            "Epoch 3/5\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.9195 - loss: 0.2146 - val_accuracy: 0.9157 - val_loss: 0.2349\n",
            "Epoch 4/5\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.9346 - loss: 0.1787 - val_accuracy: 0.9172 - val_loss: 0.2233\n",
            "Epoch 5/5\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.9437 - loss: 0.1480 - val_accuracy: 0.9187 - val_loss: 0.2300\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9091 - loss: 0.2532\n",
            "Test loss: 0.24371562898159027\n",
            "Test accuracy: 0.9126999974250793\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
            "Predicted label for first test image: 9\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_X, train_Y_one_hot, batch_size=64, epochs=10, validation_split=0.1)"
      ],
      "metadata": {
        "id": "odMH_jn2PR2P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ccb4ddf-3c87-43d5-92fe-94d952b4680a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - accuracy: 0.9521 - loss: 0.1274 - val_accuracy: 0.9220 - val_loss: 0.2401\n",
            "Epoch 2/10\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.9594 - loss: 0.1115 - val_accuracy: 0.9113 - val_loss: 0.2618\n",
            "Epoch 3/10\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.9665 - loss: 0.0874 - val_accuracy: 0.9232 - val_loss: 0.2407\n",
            "Epoch 4/10\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.9729 - loss: 0.0738 - val_accuracy: 0.9238 - val_loss: 0.2873\n",
            "Epoch 5/10\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.9770 - loss: 0.0633 - val_accuracy: 0.9258 - val_loss: 0.3017\n",
            "Epoch 6/10\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.9789 - loss: 0.0540 - val_accuracy: 0.9215 - val_loss: 0.3004\n",
            "Epoch 7/10\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.9834 - loss: 0.0448 - val_accuracy: 0.9210 - val_loss: 0.2990\n",
            "Epoch 8/10\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.9868 - loss: 0.0357 - val_accuracy: 0.9185 - val_loss: 0.3481\n",
            "Epoch 9/10\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.9866 - loss: 0.0383 - val_accuracy: 0.9218 - val_loss: 0.3428\n",
            "Epoch 10/10\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.9891 - loss: 0.0305 - val_accuracy: 0.9225 - val_loss: 0.3451\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7c7f4c353410>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_X, train_Y_one_hot, batch_size=64, epochs=20, validation_split=0.1)"
      ],
      "metadata": {
        "id": "Fg2SXkhGPVX3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e36ba090-7afa-4634-8da4-0c4050624896"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.9904 - loss: 0.0286 - val_accuracy: 0.9197 - val_loss: 0.3981\n",
            "Epoch 2/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.9902 - loss: 0.0282 - val_accuracy: 0.9152 - val_loss: 0.4708\n",
            "Epoch 3/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.9894 - loss: 0.0297 - val_accuracy: 0.9220 - val_loss: 0.4555\n",
            "Epoch 4/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.9921 - loss: 0.0240 - val_accuracy: 0.9128 - val_loss: 0.4823\n",
            "Epoch 5/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.9905 - loss: 0.0285 - val_accuracy: 0.9173 - val_loss: 0.4240\n",
            "Epoch 6/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.9922 - loss: 0.0220 - val_accuracy: 0.9213 - val_loss: 0.4634\n",
            "Epoch 7/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.9933 - loss: 0.0198 - val_accuracy: 0.9222 - val_loss: 0.4647\n",
            "Epoch 8/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.9920 - loss: 0.0245 - val_accuracy: 0.9225 - val_loss: 0.4891\n",
            "Epoch 9/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.9946 - loss: 0.0158 - val_accuracy: 0.9253 - val_loss: 0.4847\n",
            "Epoch 10/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.9931 - loss: 0.0216 - val_accuracy: 0.9223 - val_loss: 0.4453\n",
            "Epoch 11/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.9943 - loss: 0.0162 - val_accuracy: 0.9213 - val_loss: 0.5191\n",
            "Epoch 12/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9945 - loss: 0.0159 - val_accuracy: 0.9167 - val_loss: 0.5598\n",
            "Epoch 13/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.9937 - loss: 0.0205 - val_accuracy: 0.9173 - val_loss: 0.5516\n",
            "Epoch 14/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.9915 - loss: 0.0261 - val_accuracy: 0.9232 - val_loss: 0.5387\n",
            "Epoch 15/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.9944 - loss: 0.0163 - val_accuracy: 0.9205 - val_loss: 0.5707\n",
            "Epoch 16/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.9948 - loss: 0.0179 - val_accuracy: 0.9210 - val_loss: 0.4713\n",
            "Epoch 17/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.9958 - loss: 0.0120 - val_accuracy: 0.9145 - val_loss: 0.5371\n",
            "Epoch 18/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.9938 - loss: 0.0191 - val_accuracy: 0.9212 - val_loss: 0.6082\n",
            "Epoch 19/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.9939 - loss: 0.0190 - val_accuracy: 0.9230 - val_loss: 0.4929\n",
            "Epoch 20/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.9943 - loss: 0.0185 - val_accuracy: 0.9178 - val_loss: 0.5605\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7c7f4c54f1d0>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import keras\n",
        "from keras.datasets import fashion_mnist\n",
        "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
        "from keras.models import Sequential\n",
        "from keras.utils import to_categorical\n",
        "import numpy as np\n",
        "\n",
        "start_time = time.time()  # Start timer\n",
        "\n",
        "# Load and preprocess data\n",
        "(train_X, train_Y), (test_X, test_Y) = fashion_mnist.load_data()\n",
        "train_X = train_X.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
        "test_X = test_X.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
        "train_Y_one_hot = to_categorical(train_Y)\n",
        "test_Y_one_hot = to_categorical(test_Y)\n",
        "\n",
        "# Model definition\n",
        "model = Sequential()\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(28, 28, 1)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=keras.optimizers.Adam(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model for 10 epochs (or change as you want)\n",
        "model.fit(train_X, train_Y_one_hot, batch_size=64, epochs=5, validation_split=0.1, verbose=2)\n",
        "\n",
        "# Evaluate model\n",
        "test_loss, test_acc = model.evaluate(test_X, test_Y_one_hot, verbose=0)\n",
        "\n",
        "end_time = time.time()  # End timer\n",
        "\n",
        "elapsed_time = end_time - start_time\n",
        "\n",
        "print(f\"Test accuracy: {test_acc:.4f}\")\n",
        "print(f\"Total training + evaluation time: {elapsed_time:.2f} seconds\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SwclFFUXUcG4",
        "outputId": "da229529-90b8-4a0d-b4ae-5922571c17b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "844/844 - 16s - 19ms/step - accuracy: 0.8369 - loss: 0.4401 - val_accuracy: 0.8882 - val_loss: 0.2955\n",
            "Epoch 2/5\n",
            "844/844 - 6s - 7ms/step - accuracy: 0.9021 - loss: 0.2651 - val_accuracy: 0.9088 - val_loss: 0.2506\n",
            "Epoch 3/5\n",
            "844/844 - 10s - 12ms/step - accuracy: 0.9187 - loss: 0.2199 - val_accuracy: 0.9192 - val_loss: 0.2275\n",
            "Epoch 4/5\n",
            "844/844 - 6s - 7ms/step - accuracy: 0.9319 - loss: 0.1838 - val_accuracy: 0.9180 - val_loss: 0.2305\n",
            "Epoch 5/5\n",
            "844/844 - 6s - 7ms/step - accuracy: 0.9411 - loss: 0.1580 - val_accuracy: 0.9232 - val_loss: 0.2285\n",
            "Test accuracy: 0.9176\n",
            "Total training + evaluation time: 52.74 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import keras\n",
        "from keras.datasets import fashion_mnist\n",
        "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
        "from keras.models import Sequential\n",
        "from keras.utils import to_categorical\n",
        "import numpy as np\n",
        "\n",
        "start_time = time.time()  # Start timer\n",
        "\n",
        "# Load and preprocess data\n",
        "(train_X, train_Y), (test_X, test_Y) = fashion_mnist.load_data()\n",
        "train_X = train_X.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
        "test_X = test_X.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
        "train_Y_one_hot = to_categorical(train_Y)\n",
        "test_Y_one_hot = to_categorical(test_Y)\n",
        "\n",
        "# Model definition\n",
        "model = Sequential()\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(28, 28, 1)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=keras.optimizers.Adam(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model for 10 epochs (or change as you want)\n",
        "model.fit(train_X, train_Y_one_hot, batch_size=64, epochs=10, validation_split=0.1, verbose=2)\n",
        "\n",
        "# Evaluate model\n",
        "test_loss, test_acc = model.evaluate(test_X, test_Y_one_hot, verbose=0)\n",
        "\n",
        "end_time = time.time()  # End timer\n",
        "\n",
        "elapsed_time = end_time - start_time\n",
        "\n",
        "print(f\"Test accuracy: {test_acc:.4f}\")\n",
        "print(f\"Total training + evaluation time: {elapsed_time:.2f} seconds\")\n"
      ],
      "metadata": {
        "id": "qzeNjbtOU_4P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f4597b5-5b7d-4ce2-ab69-46410f3a08c0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "844/844 - 17s - 20ms/step - accuracy: 0.8401 - loss: 0.4339 - val_accuracy: 0.8960 - val_loss: 0.2833\n",
            "Epoch 2/10\n",
            "844/844 - 6s - 7ms/step - accuracy: 0.9035 - loss: 0.2636 - val_accuracy: 0.9023 - val_loss: 0.2725\n",
            "Epoch 3/10\n",
            "844/844 - 10s - 12ms/step - accuracy: 0.9189 - loss: 0.2188 - val_accuracy: 0.9148 - val_loss: 0.2318\n",
            "Epoch 4/10\n",
            "844/844 - 11s - 12ms/step - accuracy: 0.9302 - loss: 0.1861 - val_accuracy: 0.9142 - val_loss: 0.2337\n",
            "Epoch 5/10\n",
            "844/844 - 6s - 7ms/step - accuracy: 0.9414 - loss: 0.1566 - val_accuracy: 0.9175 - val_loss: 0.2225\n",
            "Epoch 6/10\n",
            "844/844 - 6s - 7ms/step - accuracy: 0.9503 - loss: 0.1348 - val_accuracy: 0.9242 - val_loss: 0.2266\n",
            "Epoch 7/10\n",
            "844/844 - 10s - 12ms/step - accuracy: 0.9578 - loss: 0.1131 - val_accuracy: 0.9163 - val_loss: 0.2577\n",
            "Epoch 8/10\n",
            "844/844 - 10s - 12ms/step - accuracy: 0.9650 - loss: 0.0939 - val_accuracy: 0.9203 - val_loss: 0.2379\n",
            "Epoch 9/10\n",
            "844/844 - 10s - 12ms/step - accuracy: 0.9702 - loss: 0.0799 - val_accuracy: 0.9102 - val_loss: 0.3400\n",
            "Epoch 10/10\n",
            "844/844 - 7s - 8ms/step - accuracy: 0.9738 - loss: 0.0689 - val_accuracy: 0.9242 - val_loss: 0.2780\n",
            "Test accuracy: 0.9194\n",
            "Total training + evaluation time: 109.75 seconds\n"
          ]
        }
      ]
    }
  ]
}